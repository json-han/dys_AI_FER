{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1단계: HardlyHumans 모델로 감정 예측\n",
    "\n",
    "**목적:** 이 노트북은 `HardlyHumans/Facial-expression-detection` 모델을 로드하고, `Data/EST_data` 디렉토리의 이미지(train, validation, test 세트)를 처리하여 예측을 생성합니다. 통합된 결과를 단일 CSV 파일로 저장합니다.\n",
    "\n",
    "**이전 버전과의 주요 변경 사항:**\n",
    "- `map_label` 함수 (fear -> panic)가 제거되었습니다.\n",
    "- 단일 함수가 `img_train`, `img_val`, `img_test` 디렉토리를 처리합니다.\n",
    "- `dataset` 열이 포함된 `02_prediction_results_all.csv`라는 단일 CSV 파일을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "/workspace/miniconda3/envs/mlflow_env/lib/python3.11/site-packages/transformers/models/vit/feature_extraction_vit.py:30: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 라벨: {0: 'anger', 1: 'contempt', 2: 'disgust', 3: 'fear', 4: 'happy', 5: 'neutral', 6: 'sad', 7: 'surprise'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, pipeline, ViTImageProcessor\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import est_utils as utils # est_utils 모듈 임포트\n",
    "\n",
    "# 사전 훈련된 모델 및 프로세서 로드\n",
    "model_name = \"HardlyHumans/Facial-expression-detection\"\n",
    "pipe = pipeline(\"image-classification\", model=model_name, device=0) # GPU 사용 가능 시 GPU 사용\n",
    "\n",
    "# processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "processor = ViTImageProcessor.from_pretrained(model_name, use_fast=True)\n",
    "model = AutoModelForImageClassification.from_pretrained(model_name)\n",
    "\n",
    "labels = model.config.id2label  # 모델 클래스 라벨(8가지)\n",
    "print(f\"모델 라벨: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 파일 탐색 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_files(base_dir, img_splits, classes):\n",
    "    \"\"\"\n",
    "    지정된 데이터셋 유형 폴더(img_train, img_val, img_test)의 모든 이미지 파일을 찾습니다.\n",
    "    이미지 경로, 실제 라벨, 데이터셋 유형이 포함된 딕셔너리 리스트를 반환합니다.\n",
    "    \"\"\"\n",
    "    all_files = []\n",
    "    for split in img_splits:\n",
    "        data_dir = os.path.join(base_dir, split)\n",
    "        if not os.path.isdir(data_dir):\n",
    "            print(f\"경고: 디렉토리를 찾을 수 없어 건너뜁니다: {data_dir}\")\n",
    "            continue\n",
    "            \n",
    "        for emotion_folder in classes:\n",
    "            emotion_dir = os.path.join(data_dir, emotion_folder)\n",
    "            if os.path.isdir(emotion_dir):\n",
    "                for filename in os.listdir(emotion_dir):\n",
    "                    if filename.lower().endswith((\".jpg\", \".jpeg\")):\n",
    "                        all_files.append({\n",
    "                            'image_path': os.path.join(emotion_dir, filename),\n",
    "                            'true_label': emotion_folder,\n",
    "                            'dataset': split.replace('img_', '')\n",
    "                        })\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 처리 및 예측 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리할 이미지 8396개를 찾았습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "이미지 처리 중:   0%|          | 10/8396 [00:02<21:37,  6.46it/s] You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "이미지 처리 중: 100%|██████████| 8396/8396 [15:24<00:00,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "총 8396개의 이미지를 성공적으로 처리했습니다.\n",
      "결과가 03_prediction_results_all.csv에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_files_to_process = get_image_files(utils.BASE_DIR, utils.IMG_SPLITS, utils.CLASSES)\n",
    "\n",
    "if not image_files_to_process:\n",
    "    print(\"이미지 파일을 찾을 수 없습니다. 디렉토리 구조와 경로를 확인하세요.\")\n",
    "else:\n",
    "    print(f\"처리할 이미지 {len(image_files_to_process)}개를 찾았습니다.\")\n",
    "    results = []\n",
    "    for item in tqdm(image_files_to_process, desc=\"이미지 처리 중\"):\n",
    "        try:\n",
    "            img = Image.open(item['image_path']).convert('RGB')\n",
    "            prediction = pipe(img)\n",
    "            predicted_label = prediction[0]['label']\n",
    "            results.append({\n",
    "                'image_path': item['image_path'],\n",
    "                'true_label': item['true_label'],\n",
    "                'predicted_label': predicted_label,\n",
    "                'dataset': item['dataset']\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"{item['image_path']} 처리 중 오류 발생: {e}\")\n",
    "            \n",
    "    # 데이터프레임을 생성하고 단일 CSV 파일로 저장\n",
    "    results_df = pd.DataFrame(results)\n",
    "    output_path = '02_prediction_results_all.csv'\n",
    "    results_df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"\\n총 {len(results_df)}개의 이미지를 성공적으로 처리했습니다.\")\n",
    "    print(f\"결과가 {output_path}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 샘플 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 데이터 샘플:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "true_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "predicted_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "b77ba462-7745-4c84-b7c3-5483aa5506e3",
       "rows": [
        [
         "0",
         "/workspace/AI/FER/Data/EST_data/img_train/anger/zzfs153e94109c926e57ec459131cc6db5934544ee63c625589a595b55ca0zuee.jpg",
         "anger",
         "surprise",
         "train"
        ],
        [
         "1",
         "/workspace/AI/FER/Data/EST_data/img_train/anger/zyct94aba1ee0d1e6292f6f56ecdba6d29a5b6e1ca43b6ab9a9b1fa1fc7a2lv51.jpg",
         "anger",
         "neutral",
         "train"
        ],
        [
         "2",
         "/workspace/AI/FER/Data/EST_data/img_train/anger/zybhf86ef77e020261b33724557a6f881876051e2e67898514564afe84e019f81.jpg",
         "anger",
         "neutral",
         "train"
        ],
        [
         "3",
         "/workspace/AI/FER/Data/EST_data/img_train/anger/zy326c174c014be2ded498c447f94dc091ff4fd0c142ddc5b7efe9703300ccp2v.jpg",
         "anger",
         "neutral",
         "train"
        ],
        [
         "4",
         "/workspace/AI/FER/Data/EST_data/img_train/anger/zx1z7a73d6976eee78347847db5180b094fe70e7aa0920ed29b54189936daz9f0.jpg",
         "anger",
         "neutral",
         "train"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/workspace/AI/FER/Data/EST_data/img_train/ange...</td>\n",
       "      <td>anger</td>\n",
       "      <td>surprise</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/workspace/AI/FER/Data/EST_data/img_train/ange...</td>\n",
       "      <td>anger</td>\n",
       "      <td>neutral</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/workspace/AI/FER/Data/EST_data/img_train/ange...</td>\n",
       "      <td>anger</td>\n",
       "      <td>neutral</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/workspace/AI/FER/Data/EST_data/img_train/ange...</td>\n",
       "      <td>anger</td>\n",
       "      <td>neutral</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/workspace/AI/FER/Data/EST_data/img_train/ange...</td>\n",
       "      <td>anger</td>\n",
       "      <td>neutral</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path true_label  \\\n",
       "0  /workspace/AI/FER/Data/EST_data/img_train/ange...      anger   \n",
       "1  /workspace/AI/FER/Data/EST_data/img_train/ange...      anger   \n",
       "2  /workspace/AI/FER/Data/EST_data/img_train/ange...      anger   \n",
       "3  /workspace/AI/FER/Data/EST_data/img_train/ange...      anger   \n",
       "4  /workspace/AI/FER/Data/EST_data/img_train/ange...      anger   \n",
       "\n",
       "  predicted_label dataset  \n",
       "0        surprise   train  \n",
       "1         neutral   train  \n",
       "2         neutral   train  \n",
       "3         neutral   train  \n",
       "4         neutral   train  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'results_df' in locals():\n",
    "    print(\"생성된 데이터 샘플:\")\n",
    "    display(results_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
