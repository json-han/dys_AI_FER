{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: 라이브러리 임포트 및 설정\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from transformers import ViTImageProcessor, AutoModelForImageClassification\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# est_utils.py에서 필요한 함수 및 상수 임포트\n",
    "from est_utils import correct_image_orientation, BACKBONE_CLASSES, FONT_PROP\n",
    "\n",
    "# 추론 설정\n",
    "config = {\n",
    "    \"mlflow_tracking_uri\": \"http://0.0.0.0:5000\",\n",
    "    \"model_load_type\": \"mlflow_run_id\", # \"mlflow_run_id\", \"local_path\", \"base_model\" 중 선택\n",
    "    \"mlflow_run_id\": \"fcc0807a25784362868877b32743a3fc\", # model_load_type이 \"mlflow_run_id\"일 경우 필요\n",
    "    \"local_model_path\": \"/workspace/AI/mlruns/1/models/m-8d2c3bcd04524f3aa4af1f7a4bd46f57/artifacts/\", # model_load_type이 \"local_path\"일 경우 필요\n",
    "    \"base_model_name\": \"HardlyHumans/Facial-expression-detection\", # model_load_type이 \"base_model\"일 경우 필요\n",
    "    \"inference_image_directory\": \"./Data/Google_search/\" # 추론할 이미지가 있는 디렉토리\n",
    "}\n",
    "\n",
    "# MLflow 트래킹 서버 URI 설정\n",
    "mlflow.set_tracking_uri(config[\"mlflow_tracking_uri\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unmatched '[' (4021748452.py, line 11)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmodel_uri = f\"runs:/{config[\"mlflow_run_id\"]}/emotion_fine_tuned_model\"\u001b[39m\n                                 ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m f-string: unmatched '['\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: 모델 로딩 함수 (load_model_for_inference)\n",
    "def load_model_for_inference(config, device):\n",
    "    \"\"\"\n",
    "    설정된 방식에 따라 모델과 프로세서를 로드합니다.\n",
    "    \"\"\"\n",
    "    model = None\n",
    "    processor = None\n",
    "\n",
    "    if config[\"model_load_type\"] == \"mlflow_run_id\":\n",
    "        try:\n",
    "            model_uri = f\"runs:/{config[\"mlflow_run_id\"]}/emotion_fine_tuned_model\"\n",
    "            model = mlflow.pytorch.load_model(model_uri)\n",
    "            print(f\"MLflow run_id: {config[\"mlflow_run_id\"]}에서 모델을 성공적으로 로드했습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"MLflow 모델 로드 실패: {e}. 로컬 백본 모델로 폴백합니다.\")\n",
    "            config[\"model_load_type\"] = \"base_model\" # 폴백\n",
    "\n",
    "    if config[\"model_load_type\"] == \"local_path\":\n",
    "        try:\n",
    "            model = mlflow.pytorch.load_model(config[\"local_model_path\"])\n",
    "            print(f\"로컬 경로: {config[\"local_model_path\"]}에서 모델을 성공적으로 로드했습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"로컬 경로 모델 로드 실패: {e}. 로컬 백본 모델로 폴백합니다.\")\n",
    "            config[\"model_load_type\"] = \"base_model\" # 폴백\n",
    "\n",
    "    if config[\"model_load_type\"] == \"base_model\" or model is None:\n",
    "        try:\n",
    "            model = AutoModelForImageClassification.from_pretrained(config[\"base_model_name\"])\n",
    "            print(f\"백본 모델 {config[\"base_model_name\"]}을 로드했습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"백본 모델 로드 실패: {e}. 모델을 로드할 수 없습니다.\")\n",
    "            return None, None\n",
    "\n",
    "    processor = ViTImageProcessor.from_pretrained(config[\"base_model_name\"], use_fast=True)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model, processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: 추론 함수 (perform_image_inference)\n",
    "def perform_image_inference(image_path, model, processor, device, backbone_classes, correct_image_orientation_func):\n",
    "    \"\"\"\n",
    "    단일 이미지에 대해 감정 추론을 수행하고 결과를 출력합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        image = correct_image_orientation_func(image)\n",
    "        image = image.convert(\"RGB\")\n",
    "        \n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Image: {os.path.basename(image_path)}', fontproperties=FONT_PROP)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        inputs = processor(images=image, return_tensors=\"pt\")\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probabilities = torch.softmax(logits, dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "        print(\"\\n==== 감정 분류 결과 ====\")\n",
    "        sorted_indices = np.argsort(probabilities)[::-1]\n",
    "        \n",
    "        for i in sorted_indices:\n",
    "            emotion = backbone_classes[i]\n",
    "            probability = probabilities[i]\n",
    "            print(f\"[{emotion}]: {probability:.4f}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"오류: '{image_path}' 파일을 찾을 수 없습니다. 경로를 확인해 주세요.\")\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: 메인 추론 루프\n",
    "model, processor = load_model_for_inference(config, device)\n",
    "\n",
    "if model and processor:\n",
    "    image_paths = glob.glob(os.path.join(config[\"inference_image_directory\"], '*.jpg')) + \\\n",
    "                  glob.glob(os.path.join(config[\"inference_image_directory\"], '*.png')) + \\\n",
    "                  glob.glob(os.path.join(config[\"inference_image_directory\"], '*.jpeg'))\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"경고: {config[\"inference_image_directory\"]} 디렉토리에서 이미지 파일을 찾을 수 없습니다.\")\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        perform_image_inference(img_path, model, processor, device, BACKBONE_CLASSES, correct_image_orientation)\n",
    "else:\n",
    "    print(\"모델 로드에 실패하여 추론을 수행할 수 없습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
